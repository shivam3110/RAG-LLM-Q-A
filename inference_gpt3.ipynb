{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCPOLHMKyA6I",
        "outputId": "8b1a0a5a-3ae3-4be0-bef5-81626b44ff72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.1/803.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q faiss-cpu\n",
        "!pip install pypdf\n",
        "!pip install -q openai\n",
        "!pip install -q tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wbPBxK-yRqF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import TextLoader,PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter,TextSplitter,CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2aaM1bYx55P"
      },
      "outputs": [],
      "source": [
        "clean_df = pd.read_json('path_to_cleaned_json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_G69RWyyVWv"
      },
      "outputs": [],
      "source": [
        "list_of_documents=[]\n",
        " \n",
        "for clean_exp in clean_df.head(1000).clean_explanation.values:\n",
        "  text_splitter = CharacterTextSplitter(separator='\\n',chunk_size=256,chunk_overlap=16)s\n",
        "  list_of_documents.extend(text_splitter.split_documents([Document(page_content=clean_exp)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP5VBbzRcQLP"
      },
      "outputs": [],
      "source": [
        "for pdf in [\"pdf1_path\",\"pdf2_path\"]:\n",
        "  loader = PyPDFLoader(pdf)\n",
        "  pages = loader.load_and_split()\n",
        "  list_of_documents.extend(text_splitter.split_documents(pages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9WfyYQdybZV"
      },
      "outputs": [],
      "source": [
        "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "\n",
        "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
        "model_kwargs = {'device':'cpu'}\n",
        "\n",
        "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "\n",
        "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=modelPath,     # Provide the pre-trained model's path\n",
        "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
        "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JB_Xdez0THA"
      },
      "outputs": [],
      "source": [
        "db = FAISS.from_documents(list_of_documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAiemvNS6EWW"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"api_key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul0qMKYK6mMG"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 10}\n",
        ")\n",
        "# create a chain to answer questions\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(temperature=0.5),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccO_fzva8LgO",
        "outputId": "1742aa70-b719-4146-a805-f760d345efba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'For the questionMountain waves should be expected..? choose the correct answer from the following answers 1 directly over the mountain range,2 on the downwind side of the mountain range.3 on the upwind side of the mountain range.4 when instability is high.',\n",
              " 'result': ' 2. on the downwind side of the mountain range.',\n",
              " 'source_documents': [Document(page_content='10.  A mountain range is aligned in an east/west direction. Select the conditions from \\nthe table below that will give rise to mountain waves:\\n 2000 ft  5000 ft  10 000 ft \\na. 020/40  020/30  020/50 \\nb. 170/20  190/40  210/60\\nc. 270/15  270/20  270/40\\nd. 090/20  090/40  090/60\\n11.  For mountain waves to form, the wind direction must be near perpendicular to a \\nridge or range of mountains and the speed must:\\na. decrease with height within a stable layer above the hill', metadata={'source': '/content/vdoc.pub_cae-oxford-aviation-academy-atpl-book-9-meteorology.pdf', 'page': 126}),\n",
              "  Document(page_content='stable air above and belowFigure 8.1 Thermal Turbulence\\nFigure 10.2.  Mechanical Turbulence.Figure 8.2 Mechanical Turbulence\\nFigure 8.3 Conditions necessary for the formation of \\nmountain waves', metadata={'source': '/content/vdoc.pub_cae-oxford-aviation-academy-atpl-book-9-meteorology.pdf', 'page': 111}),\n",
              "  Document(page_content='30\\n553\\n30 Questions                                                                               Questions\\n16. How do you recognize high level jet streams and associated CAT?\\na. High pressure centre at high level\\nb. Streaks of cirrus\\nc. High level dust\\nd. Lenticularis\\n17. Which conditions lead to mountain waves?\\na. Unstable moist air, speeds <5 kt across the ridge\\nb. Stable air, speed, >20 kt across the ridge\\nc. Unstable air, speed >20 kt across the ridge\\nd. Stable air, speed >30 kt, parallel to the ridge', metadata={'source': '/content/vdoc.pub_cae-oxford-aviation-academy-atpl-book-9-meteorology.pdf', 'page': 558}),\n",
              "  Document(page_content='Questions\\n8\\n120\\n8 Questions\\nRefer to the diagram (Appendix A) below, for questions 5-8, assuming mountain waves are \\npresent.\\nAppendix A\\n5. The wind at square A3 is likely to be:\\na. 35 kt \\nb. 50 kt \\nc. 25 kt \\nd. light\\n6. The wind at ABC 4 may be:\\na. 50 kt \\nb. 40 kt \\nc. 35 kt\\nd. a jet stream\\n7. Flight conditions at B1 are likely to be:\\na. smooth\\nb. turbulent\\nc. turbulent in breaking wave crests\\nd. turbulent due to marked up and down currents\\n8. The most extreme turbulence can occur:\\na. at B1\\nb. at A2', metadata={'source': '/content/vdoc.pub_cae-oxford-aviation-academy-atpl-book-9-meteorology.pdf', 'page': 125}),\n",
              "  Document(page_content='.\\nMOUNTAIN WAVES.\\nOscillations to the lee side (downwind)\\nof high ground resulting from the disturbance in the horizontal air flow caused by the high ground.\\nMountain waves are the result of flowing air being forced to rise up the windward side of a mountain barrier, then as a result of certain atmospheric conditions, sinking down the leeward side. This develops a series of standing waves downstream from the barrier and may extend for hundreds of kilometres over clear areas of land and open water.\\nDEFENCES:')]}"
            ]
          },
          "execution_count": 584,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa(\"For the question\"+ \"Mountain waves should be expected..? choose the correct answer from the following answers 1 directly over the mountain range,2 on the downwind side of the mountain range.3 on the upwind side of the mountain range.4 when instability is high.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v_x3xFN8Xog"
      },
      "outputs": [],
      "source": [
        "answers=[]\n",
        "sources=[]\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(1000,1452)):\n",
        "  question=clean_df['question'].iloc[i]\n",
        "  option1=clean_df['answers'].iloc[i][0]['answer']\n",
        "  option2=clean_df['answers'].iloc[i][1]['answer']\n",
        "  option3=clean_df['answers'].iloc[i][2]['answer']\n",
        "  option4=clean_df['answers'].iloc[i][3]['answer']\n",
        "  # question=\"For the question\"+ question +\"choose the correct answer from the following answers\" + option1 +\",\"+ option2 +\",\"+ option3 + \",\"+option4\n",
        "  question=\"You are an aspiring Pilot. To get the Pilot license you have to clear the exam which consists of meterology, physics and maths topics. For the question: \"+ question +\" ,return only the exact string of the correct answer from the following options: \" + option1 +\", \"+ option2 +\", \"+ option3 + \", \"+option4\n",
        "  response = qa({\"query\": question},return_only_outputs=True)\n",
        "  sources.append(response['source_documents'])\n",
        "  #print(response['result'])\n",
        "  answers.append(response['result'].lower().replace(clean_df['question'].iloc[i].lower(),'').strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBvgwQMt8hOT"
      },
      "outputs": [],
      "source": [
        "columns = ['predicted_answer', 'groundtruth', 'matches?','options','source']  # Replace with your column names\n",
        "result_df = pd.DataFrame(columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJZbtkYm8km_"
      },
      "outputs": [],
      "source": [
        "result_df['groundtruth'] = result_df['groundtruth'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc5o9Czs8r5U",
        "outputId": "752ff039-8054-4470-8251-8245fcaeb8b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "229 out of 389 are correct\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "cnt=0\n",
        "j=0\n",
        "for i in range(len(answers)):\n",
        "  matches=0\n",
        "  if answers[j].lower().strip().translate(str.maketrans('', '', string.punctuation)).replace('.','')==clean_df.tail(452)['correct_answer'].values[i].lower().strip().translate(str.maketrans('', '', string.punctuation)).replace('.',''):\n",
        "    cnt+=1\n",
        "    matches=1\n",
        "\n",
        "  row_data = {'source': sources[j], 'predicted_answer': answers[j], 'groundtruth': clean_df.tail(452)['correct_answer'].values[i], 'matches?': matches, 'options':clean_df.tail(452)['answers'].values[i]}  # Replace with your values\n",
        "  result_df = result_df.append(row_data, ignore_index=True)\n",
        "  j+=1\n",
        "print(str(cnt)+\" out of \" + str(len(answers))+\" are correct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JQsL4Czd8uyf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rouge_l_score(reference, generated):\n",
        "    smoothing_function = SmoothingFunction().method1  # Choose a smoothing function\n",
        "\n",
        "    # Tokenize the strings into lists of words\n",
        "    reference_tokens = reference.split()\n",
        "    generated_tokens = generated.split()\n",
        "\n",
        "    # Compute ROUGE-L score\n",
        "    rouge_l = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "    return rouge_l\n",
        "\n",
        "\n",
        "def map_to_option_id_gd(row):\n",
        "  target_answer=row['groundtruth']\n",
        "  answer_options=row['options']\n",
        "  for option in answer_options:\n",
        "      if target_answer.lower() in option['answer'].lower():\n",
        "          return int(option['id'])\n",
        "  return None\n",
        "\n",
        "def map_to_option_id_pred(row):\n",
        "  target_answer=row['predicted_answer']\n",
        "  answer_options=row['options']\n",
        "  maxrouge=0\n",
        "  id=None\n",
        "  for option in answer_options:\n",
        "      rouge_lscore=rouge_l_score(option['answer'].lower(),target_answer.lower())\n",
        "      if rouge_lscore > maxrouge:\n",
        "          maxrouge=rouge_lscore\n",
        "          id=int(option['id'])\n",
        "  return id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_Rny2EBMEdOr"
      },
      "outputs": [],
      "source": [
        "result_df['result_id_groundtruth'] = result_df.apply(map_to_option_id_gd, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zLtU13Xs80zZ"
      },
      "outputs": [],
      "source": [
        "result_df['result_id_prediction']=result_df.apply(map_to_option_id_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4ILIDlLL83KK"
      },
      "outputs": [],
      "source": [
        "result_df['matches_ids']=result_df.result_id_groundtruth==result_df.result_id_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Dczd8T86LG",
        "outputId": "208ef5ea-c1f4-4505-a235-8cdcbcef91af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6084070796460177"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df.matches_ids.value_counts()[True]/len(result_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
