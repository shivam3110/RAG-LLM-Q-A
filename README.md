# RAG-LLM-Question-Answer Bot

## Overview

This repository contains the solution for a case study focused on constructing a RAG (Retrieval-Augmented Generator) / LLM (Language Model) system. The primary goal is to optimize the system's performance to achieve the highest accuracy in a hypothetical exam scenario with multiple-choice questions. The success metric is the percentage of questions answered correctly.

## Task Breakdown

### 1. Data Cleaning and Preparation

- **Load the Dataset:**
  - Utilized Python for loading the dataset as '.json'
- **Data Cleaning Steps:**
  - Performed necessary data cleaning procedures(duplicates, questions referring to images,etc.).

### 2. Exploratory Data Analysis (EDA)

- **Conducted Exploratory Analysis:**
  - Explored the dataset to gain insights into its structure and characteristics.

### 3. Data Engineering

- **Engineered the Data:**
  - Transformed the dataset as needed for the intended pipeline.
- **Rationale:**
  - Explained the reasoning behind data engineering decisions.

### 4. RAG / LLM Prototype

- **Prototype Setup:**
  - Implemented a system capable of completing a hypothetical exam.
  - Utilized any suitable technology stack.
  - Employed LLM tools, retrieval mechanisms, and problem-solving capabilities.
  - Incorporated prompting techniques or chained prompts.

### 5. Interpretation & Future Work

- **Accuracy Determination:**
  - Found a method to assess the accuracy of the prototype.
- **Improvement Suggestions:**
  - Proposed further enhancements to boost the accuracy of the approach.

## Deliverables

- A Jupyter Notebook or similar document showcasing all steps for reproducibility.
- Well-structured and commented code reflecting the thought process.
- Any additional files or resources used or created during the assignment.

## Evaluation Criteria

- **Model Accuracy:**
  - Ensured high accuracy without overfitting or data leakage.
- **Data Engineering Effectiveness:**
  - Effectively used data engineering techniques to enhance dataset quality and potential model performance.
- **Code Structure:**
  - Maintained structured and clean code.

## Instructions

- The work is the sole creation of the owner.
- Online resources can be used for reference.
- Questions for clarification or guidance can be communicated via email.
- Deliverables should be submitted via email.

---

### Repository Structure

- **/data:**
  - Contains dataset files.
- **/results:**
  - Placeholder for result files.
- **EDA.ipynb:**
  - Initial commit for exploratory data analysis.
- **LLM_RAG_Inference.ipynb:**
  - Initial commit for LLM and RAG inference.
- **LLM_finetuning_with_PEFT.ipynb:**
  - Initial commit for LLM fine-tuning with PEFT.
- **LLM_finetuning_without_PEFT.ipynb:**
  - Initial commit for LLM fine-tuning without PEFT.
- **inference_gpt3.ipynb:**
  - Initial commit for GPT-3-based inference.
- **LICENSE:**
  - MIT license for the repository.
- **README.md:**
  - Updated README.md with project details.

Feel free to explore the code and resources in the repository for a comprehensive understanding of the solution.


# RAG-LLM-Question-Answer Bot

## Overview

This repository contains the solution for a case study focused on constructing a Retrieval-Augmented Generation (RAG) system or Language Model (LLM) system. The primary goal is to optimize the system's performance in a hypothetical exam scenario by answering questions correctly. The success metric is the percentage of questions answered correctly.

## Task Breakdown

### 1. Data Cleaning and Preparation

- **Dataset Loading:** The dataset is loaded using Python to kickstart the analysis.

- **Data Cleaning:** Various data cleaning steps are performed to ensure the dataset's integrity and reliability.

### 2. Exploratory Data Analysis (EDA)

- **Exploratory Analysis:** In-depth exploration of the dataset is conducted to gain insights into its characteristics and nuances.

### 3. Data Engineering

- **Feature Engineering:** The data is engineered to suit the intended pipeline, enhancing its quality for subsequent processing.

- **Rationale Explanation:** The decisions made during data engineering are explained to provide clarity on the thought process.

### 4. RAG / LLM Prototype

- **Technology Stack:** A prototype setup is created to simulate a hypothetical exam. Any relevant technology stack is employed, and the LLM may utilize retrieval, math problem-solving abilities, or toolchains.

- **Prompting Techniques:** The system may employ various prompting techniques or chained prompts to optimize question-answering accuracy.

### 5. Interpretation & Future Work

- **Accuracy Determination:** A method to determine the accuracy of the prototype is outlined.

- **Improvement Suggestions:** Recommendations for future improvements are provided, suggesting ways to enhance the accuracy of the system.

## Repository Structure

- **`data/`:** Directory containing the dataset.

- **`results/`:** Directory for storing any additional files or resources generated during the assignment.

- **`EDA.ipynb`:** Jupyter Notebook for the Exploratory Data Analysis phase.

- **`LLM_RAG_Inference.ipynb`:** Jupyter Notebook detailing the implementation of the RAG / LLM prototype.

- **`LLM_finetuning_with_PEFT.ipynb`:** Jupyter Notebook focusing on finetuning the Language Model with additional techniques.

- **`LLM_finetuning_without_PEFT.ipynb`:** Jupyter Notebook for finetuning the Language Model without additional techniques.

- **`inference_gpt3.ipynb`:** Jupyter Notebook exploring inference using the GPT-3 model.

- **`LICENSE`:** MIT license file for the repository.

- **`README.md`:** This documentation providing an overview, task breakdown, repository structure, and evaluation criteria.

## Evaluation Criteria

- **Attained Accuracy:** The accuracy of the model is a critical factor, considering the risks of overfitting and data leakage.

- **Data Engineering:** The effectiveness of data engineering techniques in enhancing dataset quality and potential model performance.

- **Code Quality:** Structured and clean code that reflects a well-thought-out process.

## Instructions

- **Originality:** The work presented in this repository is solely the contributor's.

- **Questions:** Any queries for clarification or guidance can be directed via email.

- **Submission:** Deliverables, including a well-structured and commented Jupyter Notebook, should be submitted via email.

Feel free to explore the notebooks and directories for a detailed walkthrough of the process and outcomes of the RAG / LLM system construction.

